{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea54e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c28b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.5, 0.5, 0.5])\n",
    "std = np.array([0.25, 0.25, 0.25])\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std)\n",
    "])\n",
    "class food11:\n",
    "    def __init__(self,path,transform):\n",
    "        self.path=path\n",
    "        self.n_file=sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith('.jpg')])\n",
    "        print(self.n_file[0].replace('\\\\','/'))\n",
    "        self.sample=len(self.n_file)\n",
    "        self.transform=transform\n",
    "    def __getitem__(self,index):\n",
    "        img=Image.open(self.n_file[index].replace('\\\\','/'))\n",
    "        img=self.transform(img);\n",
    "        label=self.n_file[index].replace('\\\\','/').split(\"/\")[-1].split(\"_\")[0]\n",
    "        label=label\n",
    "        label=int(label)\n",
    "        return img,label\n",
    "    def __len__(self):\n",
    "        return self.sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61d37c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./food11/training/0_0.jpg\n"
     ]
    }
   ],
   "source": [
    "path='./food11/training'\n",
    "data=food11(path,transform)\n",
    "dataloader=torch.utils.data.DataLoader(dataset=data,batch_size=128,shuffle=True)\n",
    "x,_=iter(dataloader).next()\n",
    "\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87ce8760",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        # The arguments for commonly used modules:\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "\n",
    "        # input image size: [3, 128, 128]\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),\n",
    "            \n",
    "#             nn.Dropout2d(p=0.2),\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),\n",
    "            \n",
    "#             nn.Dropout2d(p=0.2),\n",
    "            nn.Conv2d(128, 256, 3, 1, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4, 4, 0),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(256 * 8 * 8, 256),\n",
    "#             nn.Dropout(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 11)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input (x): [batch_size, 3, 128, 128]\n",
    "        # output: [batch_size, 11]\n",
    "\n",
    "        # Extract features by convolutional layers.\n",
    "        x = self.cnn_layers(x)\n",
    "\n",
    "        # The extracted feature map must be flatten before going to fully-connected layers.\n",
    "        x = x.flatten(1)\n",
    "\n",
    "        # The features are transformed by fully-connected layers to obtain the final logits.\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "329e18ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "lr=0.0003\n",
    "n_step=len(dataloader)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfb467b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Classifier().to(device)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=lr,weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d826abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 0, step= 0/78, loss= 2.397\n",
      "epoch= 0, step= 10/78, loss= 2.183\n",
      "epoch= 0, step= 20/78, loss= 1.951\n",
      "epoch= 0, step= 30/78, loss= 1.861\n",
      "epoch= 0, step= 40/78, loss= 1.830\n",
      "epoch= 0, step= 50/78, loss= 1.958\n",
      "epoch= 0, step= 60/78, loss= 1.872\n",
      "epoch= 0, step= 70/78, loss= 1.701\n",
      "epoch= 1, step= 0/78, loss= 1.593\n",
      "epoch= 1, step= 10/78, loss= 1.673\n",
      "epoch= 1, step= 20/78, loss= 1.619\n",
      "epoch= 1, step= 30/78, loss= 1.665\n",
      "epoch= 1, step= 40/78, loss= 1.903\n",
      "epoch= 1, step= 50/78, loss= 1.387\n",
      "epoch= 1, step= 60/78, loss= 1.403\n",
      "epoch= 1, step= 70/78, loss= 1.553\n",
      "epoch= 2, step= 0/78, loss= 1.437\n",
      "epoch= 2, step= 10/78, loss= 1.466\n",
      "epoch= 2, step= 20/78, loss= 1.487\n",
      "epoch= 2, step= 30/78, loss= 1.266\n",
      "epoch= 2, step= 40/78, loss= 1.306\n",
      "epoch= 2, step= 50/78, loss= 1.365\n",
      "epoch= 2, step= 60/78, loss= 1.391\n",
      "epoch= 2, step= 70/78, loss= 1.504\n",
      "epoch= 3, step= 0/78, loss= 1.441\n",
      "epoch= 3, step= 10/78, loss= 1.238\n",
      "epoch= 3, step= 20/78, loss= 1.282\n",
      "epoch= 3, step= 30/78, loss= 1.373\n",
      "epoch= 3, step= 40/78, loss= 1.369\n",
      "epoch= 3, step= 50/78, loss= 1.469\n",
      "epoch= 3, step= 60/78, loss= 1.200\n",
      "epoch= 3, step= 70/78, loss= 1.235\n",
      "epoch= 4, step= 0/78, loss= 1.126\n",
      "epoch= 4, step= 10/78, loss= 1.126\n",
      "epoch= 4, step= 20/78, loss= 1.256\n",
      "epoch= 4, step= 30/78, loss= 1.341\n",
      "epoch= 4, step= 40/78, loss= 1.185\n",
      "epoch= 4, step= 50/78, loss= 1.142\n",
      "epoch= 4, step= 60/78, loss= 1.248\n",
      "epoch= 4, step= 70/78, loss= 0.968\n",
      "epoch= 5, step= 0/78, loss= 1.120\n",
      "epoch= 5, step= 10/78, loss= 1.248\n",
      "epoch= 5, step= 20/78, loss= 1.297\n",
      "epoch= 5, step= 30/78, loss= 1.098\n",
      "epoch= 5, step= 40/78, loss= 1.302\n",
      "epoch= 5, step= 50/78, loss= 1.146\n",
      "epoch= 5, step= 60/78, loss= 0.991\n",
      "epoch= 5, step= 70/78, loss= 1.034\n",
      "epoch= 6, step= 0/78, loss= 0.993\n",
      "epoch= 6, step= 10/78, loss= 1.224\n",
      "epoch= 6, step= 20/78, loss= 1.004\n",
      "epoch= 6, step= 30/78, loss= 0.898\n",
      "epoch= 6, step= 40/78, loss= 1.014\n",
      "epoch= 6, step= 50/78, loss= 1.149\n",
      "epoch= 6, step= 60/78, loss= 0.967\n",
      "epoch= 6, step= 70/78, loss= 0.998\n",
      "epoch= 7, step= 0/78, loss= 1.040\n",
      "epoch= 7, step= 10/78, loss= 0.959\n",
      "epoch= 7, step= 20/78, loss= 0.920\n",
      "epoch= 7, step= 30/78, loss= 0.850\n",
      "epoch= 7, step= 40/78, loss= 1.022\n",
      "epoch= 7, step= 50/78, loss= 0.893\n",
      "epoch= 7, step= 60/78, loss= 0.925\n",
      "epoch= 7, step= 70/78, loss= 0.835\n",
      "epoch= 8, step= 0/78, loss= 0.970\n",
      "epoch= 8, step= 10/78, loss= 0.937\n",
      "epoch= 8, step= 20/78, loss= 0.909\n",
      "epoch= 8, step= 30/78, loss= 0.740\n",
      "epoch= 8, step= 40/78, loss= 0.958\n",
      "epoch= 8, step= 50/78, loss= 0.938\n",
      "epoch= 8, step= 60/78, loss= 1.031\n",
      "epoch= 8, step= 70/78, loss= 0.760\n",
      "epoch= 9, step= 0/78, loss= 0.762\n",
      "epoch= 9, step= 10/78, loss= 0.867\n",
      "epoch= 9, step= 20/78, loss= 0.650\n",
      "epoch= 9, step= 30/78, loss= 0.697\n",
      "epoch= 9, step= 40/78, loss= 0.728\n",
      "epoch= 9, step= 50/78, loss= 0.663\n",
      "epoch= 9, step= 60/78, loss= 0.638\n",
      "epoch= 9, step= 70/78, loss= 0.628\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i,(x,y) in enumerate(dataloader):\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if i % 10 == 0:\n",
    "            print(f'epoch= {epoch}, step= {i}/{n_step}, loss= {loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003c2f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
